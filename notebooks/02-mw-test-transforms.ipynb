{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lightning as L\n",
    "import omegaconf\n",
    "import pyrootutils\n",
    "import torch\n",
    "import torchshow as ts\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from gaussian_denoiser import data, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pyrootutils.setup_root(\n",
    "    search_from=\".\",\n",
    "    indicator=\"pyproject.toml\",\n",
    "    project_root_env_var=True,\n",
    "    dotenv=True,\n",
    "    pythonpath=False,\n",
    "    cwd=True,\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = os.getenv(\"PROJECT_ROOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(f\"{PROJECT_ROOT}/config/train.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(123, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "ds = data.InferenceImageDataset(\n",
    "    image_dir=cfg.data.train_path,\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.CenterCrop((50, 50))]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ds[0]\n",
    "type(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.AWGNOnlyTransform(\n",
    "    min_variance=cfg.data.train_noise_level_interval[0],\n",
    "    max_variance=cfg.data.train_noise_level_interval[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_noise, noise, var = tr(image)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_tensor(image).max()\n",
    "TF.to_tensor(image).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_tensor(image_noise).max()\n",
    "TF.to_tensor(image_noise).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(noise / 255.0).max()\n",
    "(noise / 255.0).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = TF.to_tensor(image) - (TF.to_tensor(image_noise) - (noise / 255.0))\n",
    "\n",
    "torch.testing.assert_close(diff, torch.zeros_like(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.DownUpsampleTransform(factors=cfg.data.up_down_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_noise, noise = tr(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_tensor(image_noise).max()\n",
    "TF.to_tensor(image_noise).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)\n",
    "type(image_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.show(image_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = TF.to_tensor(image) - (TF.to_tensor(image_noise) - (noise / 255.0))\n",
    "\n",
    "torch.testing.assert_close(diff, torch.zeros_like(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.JPEGTransform(\n",
    "    min_quality=cfg.data.jpeg_min_max[0], max_quality=cfg.data.jpeg_min_max[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_noise, noise = tr(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.show(image)\n",
    "ts.show(image_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = TF.to_tensor(image) - (TF.to_tensor(image_noise) - (noise / 255.0))\n",
    "\n",
    "torch.testing.assert_close(diff, torch.zeros_like(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.CombinedTransform(\n",
    "    min_quality=cfg.data.jpeg_min_max[0],\n",
    "    max_quality=cfg.data.jpeg_min_max[1],\n",
    "    factors=cfg.data.up_down_factors,\n",
    "    min_variance=cfg.data.train_noise_level_interval[0],\n",
    "    max_variance=cfg.data.train_noise_level_interval[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    image_noise, noise = tr(image)\n",
    "    ts.show(image_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)\n",
    "image\n",
    "img = TF.to_tensor(image)\n",
    "img.max()\n",
    "\n",
    "img_rec = TF.to_pil_image(img)\n",
    "img_rec\n",
    "\n",
    "torch.testing.assert_close(TF.to_tensor(img_rec), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noise = transforms.AWGNOnlyTransform(\n",
    "    min_variance=cfg.data.train_noise_level_interval[0],\n",
    "    max_variance=cfg.data.train_noise_level_interval[1],\n",
    ")\n",
    "val_noise = transforms.AWGNOnlyTransform(\n",
    "    min_variance=cfg.data.val_noise_level_interval[0],\n",
    "    max_variance=cfg.data.val_noise_level_interval[1],\n",
    ")\n",
    "\n",
    "data_module = data.DenoisingDataModule(\n",
    "    train_path=cfg.data.train_path,\n",
    "    val_path=cfg.data.val_path,\n",
    "    test_path=cfg.data.test_path,\n",
    "    batch_size=16,\n",
    "    patch_size=cfg.data.patch_size,\n",
    "    train_noise=train_noise,\n",
    "    val_noise=val_noise,\n",
    ")\n",
    "\n",
    "data_module.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = data_module.train_dataloader()\n",
    "clean_batch, noisy_batch, noise_batch = next(iter(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(noisy_batch)\n",
    "torch.max(noisy_batch)\n",
    "\n",
    "torch.min(clean_batch)\n",
    "torch.max(clean_batch)\n",
    "\n",
    "torch.min(noise_batch)\n",
    "noise_batch.view(noise_batch.shape[0], -1).max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
